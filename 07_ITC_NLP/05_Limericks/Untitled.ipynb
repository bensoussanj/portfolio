{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:41:31.858944Z",
     "start_time": "2019-01-24T14:41:31.835224Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, LSTM, GRU, TimeDistributed, Dense, Activation\n",
    "from collections import Counter\n",
    "from functools import reduce\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:31.072459Z",
     "start_time": "2019-01-24T13:40:31.048111Z"
    }
   },
   "outputs": [],
   "source": [
    "# Read limericks.csv downloaded from https://github.com/sballas8/PoetRNN/blob/master/data/limericks.csv\n",
    "df_limericks = pd.read_csv('limericks.csv', names=['limericks'], nrows=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:31.611189Z",
     "start_time": "2019-01-24T13:40:31.592807Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limericks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cap'n jack was washed over the side.\\nhis crew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablactation, to wean off the breast,\\nshould w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a soup, bisque is best when served hot.\\nma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simply add to the grasp of a rhesus\\nthe antit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abed's where you sleep in the night,\\nunless y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           limericks\n",
       "0  cap'n jack was washed over the side.\\nhis crew...\n",
       "1  ablactation, to wean off the breast,\\nshould w...\n",
       "2  as a soup, bisque is best when served hot.\\nma...\n",
       "3  simply add to the grasp of a rhesus\\nthe antit...\n",
       "4  abed's where you sleep in the night,\\nunless y..."
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limericks['limericks'] = df_limericks.limericks.apply((lambda x: x.replace('\\r','')))\n",
    "df_limericks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:32.771625Z",
     "start_time": "2019-01-24T13:40:32.232460Z"
    }
   },
   "outputs": [],
   "source": [
    "letter_count = dict(reduce((lambda x, y: x + y),list(map(Counter, df_limericks['limericks'].tolist()))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:32.987944Z",
     "start_time": "2019-01-24T13:40:32.983578Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25134=+0987*/6\t&[]_#@%$\n"
     ]
    }
   ],
   "source": [
    "infrequent_chars = [k for k, v in letter_count.items() if v < 1000]\n",
    "print(''.join(infrequent_chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:33.464412Z",
     "start_time": "2019-01-24T13:40:33.432696Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>limericks</th>\n",
       "      <th>limericks_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cap'n jack was washed over the side.\\nhis crew...</td>\n",
       "      <td>cap'n jack was washed over the side.\\nhis crew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ablactation, to wean off the breast,\\nshould w...</td>\n",
       "      <td>ablactation, to wean off the breast,\\nshould w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>as a soup, bisque is best when served hot.\\nma...</td>\n",
       "      <td>as a soup, bisque is best when served hot.\\nma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>simply add to the grasp of a rhesus\\nthe antit...</td>\n",
       "      <td>simply add to the grasp of a rhesus\\nthe antit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abed's where you sleep in the night,\\nunless y...</td>\n",
       "      <td>abed's where you sleep in the night,\\nunless y...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           limericks  \\\n",
       "0  cap'n jack was washed over the side.\\nhis crew...   \n",
       "1  ablactation, to wean off the breast,\\nshould w...   \n",
       "2  as a soup, bisque is best when served hot.\\nma...   \n",
       "3  simply add to the grasp of a rhesus\\nthe antit...   \n",
       "4  abed's where you sleep in the night,\\nunless y...   \n",
       "\n",
       "                                     limericks_clean  \n",
       "0  cap'n jack was washed over the side.\\nhis crew...  \n",
       "1  ablactation, to wean off the breast,\\nshould w...  \n",
       "2  as a soup, bisque is best when served hot.\\nma...  \n",
       "3  simply add to the grasp of a rhesus\\nthe antit...  \n",
       "4  abed's where you sleep in the night,\\nunless y...  "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_limericks['limericks_clean'] = df_limericks['limericks'].str.replace(r'['+ re.escape(''.join(infrequent_chars))+ r']', '?', regex=True)\n",
    "df_limericks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:40:34.453475Z",
     "start_time": "2019-01-24T13:40:34.448543Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '^', '$', '\\n', ' ', '!', '\"', \"'\", '(', ')', ',', '-', '.', ':', ';', '?', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "valid_characters = ['0', '^', '$'] + sorted([k for k, v in letter_count.items() if k not in infrequent_chars])\n",
    "print(valid_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:57:12.735678Z",
     "start_time": "2019-01-24T13:57:10.886781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 203)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_lims = np.array([[valid_characters.index(car) for car in '^'+x[:202]+'0'*(202-len(x[:202]))+'$' if car in valid_characters] for x in df_limericks['limericks_clean'].tolist()])\n",
    "X = padded_lims[:,:203]\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:57:19.820352Z",
     "start_time": "2019-01-24T13:57:19.584642Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 203, 42)"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = padded_lims[:,1:204]\n",
    "Y = to_categorical(Y, num_classes=len(valid_characters))\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T13:02:01.410674Z",
     "start_time": "2019-01-24T13:02:01.405373Z"
    }
   },
   "source": [
    "### III. Build a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:12:08.607899Z",
     "start_time": "2019-01-24T14:12:08.183486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_11 (Embedding)     (None, None, 50)          2100      \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, None, 100)         60400     \n",
      "_________________________________________________________________\n",
      "time_distributed_9 (TimeDist (None, None, 42)          4242      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, None, 42)          0         \n",
      "=================================================================\n",
      "Total params: 66,742\n",
      "Trainable params: 66,742\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "hidden_size = 100\n",
    "voc_size = len(valid_characters)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_dim)) # E is embedding dimension, V is vocabulary size\n",
    "model.add(LSTM(hidden_size, return_sequences=True))  \n",
    "model.add(TimeDistributed(Dense(voc_size)))\n",
    "model.add(Activation('softmax'))   \n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:22:02.093302Z",
     "start_time": "2019-01-24T14:13:48.990830Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 2.4716 - acc: 0.3187\n",
      "Epoch 2/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 2.3403 - acc: 0.3581\n",
      "Epoch 3/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 2.1983 - acc: 0.3827\n",
      "Epoch 4/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 2.1033 - acc: 0.4028\n",
      "Epoch 5/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 2.0411 - acc: 0.4135\n",
      "Epoch 6/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.9881 - acc: 0.4217\n",
      "Epoch 7/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.9445 - acc: 0.4302\n",
      "Epoch 8/20\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.9046 - acc: 0.4406\n",
      "Epoch 9/20\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.8699 - acc: 0.4503\n",
      "Epoch 10/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.8400 - acc: 0.4573\n",
      "Epoch 11/20\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.8132 - acc: 0.4639\n",
      "Epoch 12/20\n",
      "10000/10000 [==============================] - 25s 3ms/step - loss: 1.7889 - acc: 0.4696\n",
      "Epoch 13/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.7662 - acc: 0.4756\n",
      "Epoch 14/20\n",
      "10000/10000 [==============================] - 25s 2ms/step - loss: 1.7452 - acc: 0.4815\n",
      "Epoch 15/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.7258 - acc: 0.4870\n",
      "Epoch 16/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.7080 - acc: 0.4918\n",
      "Epoch 17/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.6914 - acc: 0.4966\n",
      "Epoch 18/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.6760 - acc: 0.5008\n",
      "Epoch 19/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.6622 - acc: 0.5046\n",
      "Epoch 20/20\n",
      "10000/10000 [==============================] - 24s 2ms/step - loss: 1.6497 - acc: 0.5076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14398ac88>"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X,Y, batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:40:25.531852Z",
     "start_time": "2019-01-24T14:40:23.270499Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^lyieg the ellation tiflout,\n",
      "what in chammer we'nd lengine.\n",
      "lit tames, ind't soise.\n",
      "youh ax there,\n",
      "and dom taking, \"quim, \"still,\n",
      "actaredan wed whes letr, ti'soe.\n",
      "0\n",
      "====================================================================================================\n",
      "^\"wemall, busess are corlocty\n",
      "that'd lake cae borey, whing a farat!\n",
      "0\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "for j in range(2):\n",
    "    sentence = []\n",
    "    letter = [valid_characters.index('^')] #choose a random letter\n",
    "    for i in range(200):\n",
    "        sentence.append(valid_characters[letter[-1]])\n",
    "        if sentence[-1]=='$' or sentence[-1]=='0':\n",
    "            break\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(valid_characters),1,p=p[0][-1])[0])\n",
    "\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS - Use a GRU layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-01-24T14:41:36.311878Z",
     "start_time": "2019-01-24T14:41:35.987144Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_12 (Embedding)     (None, None, 50)          2100      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, None, 100)         45300     \n",
      "_________________________________________________________________\n",
      "time_distributed_10 (TimeDis (None, None, 42)          4242      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, None, 42)          0         \n",
      "=================================================================\n",
      "Total params: 51,642\n",
      "Trainable params: 51,642\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "hidden_size = 100\n",
    "voc_size = len(valid_characters)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(voc_size, embedding_dim)) # E is embedding dimension, V is vocabulary size\n",
    "model.add(GRU(hidden_size, input_shape = X.shape, return_sequences=True))  \n",
    "model.add(TimeDistributed(Dense(voc_size)))\n",
    "model.add(Activation('softmax'))   \n",
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,Y, batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(2):\n",
    "    sentence = []\n",
    "    letter = [valid_characters.index('^')] #choose a random letter\n",
    "    for i in range(200):\n",
    "        sentence.append(valid_characters[letter[-1]])\n",
    "        if sentence[-1]=='$' or sentence[-1]=='0':\n",
    "            break\n",
    "        p = model.predict(np.array(letter)[None,:])\n",
    "        letter.append(np.random.choice(len(valid_characters),1,p=p[0][-1])[0])\n",
    "\n",
    "    print(''.join(sentence))\n",
    "    print('='*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ITC]",
   "language": "python",
   "name": "conda-env-ITC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
