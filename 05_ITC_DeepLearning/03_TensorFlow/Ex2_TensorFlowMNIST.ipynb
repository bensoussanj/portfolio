{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bsh_Efrtg0nO"
   },
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "upxBDV9DI-Cf"
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from time import time\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "# matplotlib theme\n",
    "from jupyterthemes import jtplot\n",
    "jtplot.style()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "stQzJU6-ex1o"
   },
   "source": [
    "In the next exercise, we will use a neural network comprised of only fully-connected layers to classify the MNIST dataset: Here we won't use the classic 10-class classification, but classify into two classes: even digits and odd digits.\n",
    "\n",
    "The next code snippet downloads the MNIST dataset for you and defines two functions - the weights and the bias variables. \n",
    "We will use those functions to construct our network.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "b_7PB4yvhMUd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Disable warnings before download / Reenable afterwards\n",
    "old_v = tf.logging.get_verbosity()\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)\n",
    "\n",
    "# Download the dataset\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "tf.logging.set_verbosity(old_v)\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.01)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.0, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HlUyxaoghObl"
   },
   "source": [
    "\n",
    "For this, start by defining two placeholders, one to hold the images, and the second to hold the two classes.\n",
    "Use tf.float32 for the placeholder type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "g8kakhjcJIYm"
   },
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "\n",
    "# correct labels\n",
    "y_ = tf.placeholder(tf.int8, shape=[batch_size, 2])\n",
    "\n",
    "# input data\n",
    "x = tf.placeholder(tf.float32, shape=[batch_size, 784])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Od4jqtgbX1T"
   },
   "source": [
    "Next, define the network itself. It is up to you how many layers to use, and the number of hidden units in each layer.\n",
    "\n",
    "You are allowed to use only the following functions:\n",
    "* weight_variable\n",
    "* bias_variable\n",
    "* tf.nn.relu\n",
    "* tf.nn.dropout\n",
    "* tf.nn.softmax\n",
    "* tf.matmul\n",
    "\n",
    "Please note that each layer includes not only tf.matmul, but also a bias variable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "L9qEz6CjJLd2"
   },
   "outputs": [],
   "source": [
    "# build the net\n",
    "hidden_size = 6\n",
    "num_classes = 2\n",
    "neuron_per_layer = 500\n",
    "\n",
    "# Input Layer\n",
    "W_fc1 = weight_variable([784, neuron_per_layer])\n",
    "b_fc1 = bias_variable([neuron_per_layer])\n",
    "\n",
    "# Hidden Layers\n",
    "h_fch = tf.expand_dims(tf.nn.relu(tf.matmul(x, W_fc1) + b_fc1), 2)\n",
    "W_fch = weight_variable([neuron_per_layer, neuron_per_layer, hidden_size])\n",
    "for i in range(hidden_size-1):\n",
    "    mult = tf.nn.relu(tf.matmul(h_fch[:,:,i], W_fch[:,:,i])+ b_fc1)\n",
    "    h_fch = tf.concat([h_fch, tf.expand_dims(mult, 2)], 2)\n",
    "    \n",
    "# Output Layer\n",
    "W_fco = weight_variable([neuron_per_layer, num_classes])\n",
    "y = tf.matmul(h_fch[:, :, hidden_size-1], W_fco)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KF4v2BCwglVF"
   },
   "source": [
    "Complete the snippet below using your own code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VfVlJ7GQjvlD"
   },
   "source": [
    "define the loss function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vZ6wq8_cjjsl"
   },
   "outputs": [],
   "source": [
    "# define the loss function\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(logits=y,\n",
    "                                                        labels=y_)\n",
    "cost = tf.reduce_mean(cross_entropy)\n",
    "\n",
    "# define Optimizer\n",
    "Optimizer = tf.train.AdamOptimizer(1e-3).minimize(cost)\n",
    "reduction = tf.matmul(tf.reshape(tf.reduce_max(y, reduction_indices=[1]), [batch_size,1]), tf.ones([1,2]))\n",
    "\n",
    "prediction = tf.cast(tf.equal(y, reduction), tf.int8)\n",
    "correct_predictions = tf.math.equal(y_, prediction)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_predictions, tf.float32))\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6SzjkHocfb7Z"
   },
   "source": [
    "The next code snippet trains and evaluates the network. It does this by opening a session to run the tensorflow graph that we have defined.\n",
    "Complete the code at the locations marked #YOUR CODE below, in order to train the network and to evaluate its accuracy every 50 steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "VDWNSW5bf3tI",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38d7927b297a4688b259d7e2e0a75a44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=701), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0.523\n",
      "Validation accuracy: 0.508.\n",
      "step 50, training accuracy 0.945\n",
      "Validation accuracy: 0.935.\n",
      "step 100, training accuracy 0.978\n",
      "Validation accuracy: 0.978.\n",
      "step 150, training accuracy 0.992\n",
      "Validation accuracy: 0.98.\n",
      "step 200, training accuracy 0.99\n",
      "Validation accuracy: 0.987.\n",
      "step 250, training accuracy 0.993\n",
      "Validation accuracy: 0.988.\n",
      "step 300, training accuracy 0.997\n",
      "Validation accuracy: 0.984.\n",
      "step 350, training accuracy 1\n",
      "Validation accuracy: 0.99.\n",
      "step 400, training accuracy 0.998\n",
      "Validation accuracy: 0.984.\n",
      "step 450, training accuracy 1\n",
      "Validation accuracy: 0.988.\n",
      "step 500, training accuracy 0.999\n",
      "Validation accuracy: 0.987.\n",
      "step 550, training accuracy 0.997\n",
      "Validation accuracy: 0.987.\n",
      "step 600, training accuracy 0.999\n",
      "Validation accuracy: 0.984.\n",
      "step 650, training accuracy 0.999\n",
      "Validation accuracy: 0.99.\n",
      "step 700, training accuracy 1\n",
      "Validation accuracy: 0.98.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def restrict_to_2_classes(y):\n",
    "    # reduce to 2 classes: 0 for even, 1 for odd\n",
    "    return (y @ np.arange(0,10).reshape(10,1) + [0,1]) % 2\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for i in tqdm(range(701)):\n",
    "        input_images, y_train = mnist.train.next_batch(batch_size)\n",
    "        y_train = restrict_to_2_classes(y_train)\n",
    "\n",
    "        sess.run([y, cost, Optimizer], feed_dict={x: input_images, y_: y_train})\n",
    "\n",
    "        if i % 50 == 0:\n",
    "            train_accuracy = sess.run(accuracy, feed_dict={x: input_images, y_: y_train})\n",
    "            print(\"step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "\n",
    "            # validate\n",
    "            test_input_images, test_correct_predictions = mnist.test.next_batch(batch_size)\n",
    "\n",
    "            test_correct_predictions = restrict_to_2_classes(test_correct_predictions)\n",
    "            test_accuracy = sess.run(accuracy, feed_dict={x: test_input_images, y_: test_correct_predictions})\n",
    "\n",
    "            print(\"Validation accuracy: %g.\" % test_accuracy)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "tensorflow_MNIST.ipynb",
   "provenance": [
    {
     "file_id": "1twhLFBOCaDjPixASn4-zvV5aIHmYnf0Y",
     "timestamp": 1528918576198
    },
    {
     "file_id": "19RvBcD_vd27zIC3XpTUfsOoPNnRQm81A",
     "timestamp": 1528895264710
    }
   ],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python [conda env:ITC]",
   "language": "python",
   "name": "conda-env-ITC-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
